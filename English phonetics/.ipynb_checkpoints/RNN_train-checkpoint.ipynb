{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchsummary import summary \n",
    "from tqdm import trange \n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import time \n",
    "import random \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# GPU still outperfoms CPU for no vivid reason, that's why we leave this line\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEMIEUX L_AH_M_Y_UW\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "# strip removes spaces at the start and the end of each line\n",
    "# split separates the string by the provided delimeter and returns a list of strings\n",
    "\n",
    "data = open('train.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "print(data[0]) # to ensure we did everything right \n",
    "\n",
    "# hardcoding this is a bad practice that leads to a higher probability of missing something and takes a HUGE amount\n",
    "# of time, but I'll leave it as it is for now \n",
    "\n",
    "chardict =  {'': 0, '.': 1, \"'\": 2, '-':3, 'A': 4, 'B': 5, 'C': 6, 'D': 7, 'E': 8, 'F': 9, 'G': 10, 'H': 11, 'I': 12, 'J': 13, 'K': 14, 'L': 15, 'M': 16, 'N': 17, 'O': 18, 'P': 19, 'Q': 20, 'R': 21, 'S': 22, 'T': 23, 'U': 24, 'V': 25, 'W': 26, 'X': 27, 'Y': 28, 'Z': 29}\n",
    "phonedict = {'AA' : 0, 'AE' : 1, 'AH' : 2, 'AO' : 3, 'AW' : 4, 'AY' : 5, 'B' : 6, 'CH' : 7, 'D' : 8, 'DH' : 9, 'EH' : 10, 'ER' : 11, 'EY' : 12, 'F' : 13, 'G' : 14, 'HH' : 15, 'IH' : 16, 'IY' : 17, 'JH' : 18, 'K' : 19, 'L' : 20, 'M' : 21, 'N' : 22, 'NG' : 23, 'OW' : 24, 'OY' : 25, 'P' : 26, 'R' : 27, 'S' : 28, 'SH' : 29, 'T' : 30, 'TH' : 31, 'UH' : 32, 'UW' : 33, 'V' : 34, 'W' : 35, 'Y' : 36, 'Z' : 37, 'ZH' : 38}\n",
    "\n",
    "# we'll use them later for evaluation and submission\n",
    "\n",
    "rev_chardict = {v:k for k,v in chardict.items()}\n",
    "rev_phonedict = {v:k for k,v in phonedict.items()}\n",
    "\n",
    "# adding 2 for SOS and EOS tokens\n",
    "\n",
    "n_chars = len(chardict) + 2\n",
    "n_phones = len(phonedict) + 2\n",
    "n_words = len(data)\n",
    "\n",
    "# some useful functions for preparing our data to feed the network\n",
    "# note that we use one-hot encoding to get rid of nonexistent correlations that appear when we use indexing\n",
    "# I actually wanted to try embeddings, yet character-level embeddings doesn't seem to make much sense \n",
    "\n",
    "def wordToTensor(line):\n",
    "    tensor = torch.zeros(len(line) + 1, 1, n_chars)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][chardict[letter] + 2] = 1\n",
    "    tensor[len(line)][0][1] = 1\n",
    "    return tensor\n",
    "\n",
    "def phoneToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_phones)\n",
    "    linelist = line.split('_')\n",
    "    for li, letter in enumerate(linelist):\n",
    "        tensor[li][0][phonedict[letter] + 2] = 1\n",
    "    tensor[len(linelist)][0][1] = 1\n",
    "    return tensor\n",
    "\n",
    "def pairTensor(i):\n",
    "    linelist = data[i].split(' ')\n",
    "    return (wordToTensor(linelist[0]), phoneToTensor(linelist[1]))\n",
    "\n",
    "# I'm terribly sorry even this is hardcoded, I experimented with cutting off words by their size to reduce training\n",
    "# time. Actuallly it didn't give any valuable boost, so I left the whole dataset without trimming. \n",
    "\n",
    "max_wordlen = 36\n",
    "max_phonelen = 20\n",
    "\n",
    "data = [word for word in data if len(word.split(' ')[0]) <= max_wordlen]\n",
    "\n",
    "for word in data:\n",
    "    max_phonelen = max(max_phonelen, len(word.split(' ')[1]))\n",
    "    \n",
    "print(max_phonelen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256 # it sure helped to squeeze another several percent when i doubled hidden size (128->256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few words about encoder and decoder: they are done in a simplest possible manner, yet some tweaking was very \n",
    "# helpful (actually it was the thing that gave the most significant improvements, wonder how much better would \n",
    "# tweaked attention model be)\n",
    "# The first point: LSTM > GRU (yet training time is somewhat longer)\n",
    "# Second point: bidirectional LSTM > LSTM (that too gave some significant boost, multyplying training time by \n",
    "# something like 1.5 \n",
    "# Third point: dropout is crucial, and 0.5 > 0.2 (I was afraid of underfitting so I started with a lighter dropout)\n",
    "# Fourth point: 2-layer LSTM (GRU) gave better results than 1-layer and 3-layer.\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.gru = nn.LSTM(n_chars, hidden_size, batch_first = True, bidirectional = True, num_layers = 2, dropout = 0.5)\n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        output, hidden = self.gru(inp.view(1, 1, -1), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(6, 1, self.hidden_size, device=device), torch.zeros(6, 1, self.hidden_size, device=device))\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.gru = nn.LSTM(output_size, hidden_size, batch_first = True, bidirectional = True, num_layers = 2, dropout = 0.5)\n",
    "        self.out = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        output = inp.view(1, 1, -1)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "encoder = EncoderRNN(n_chars, n_hidden).to(device)\n",
    "decoder = DecoderRNN(n_hidden, n_phones).to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "# At first I forgot about lr decay and had mediocre results. Adam learning rate decay has proven to be on of the \n",
    "# most effective (yet absolutely unintuitive) practices. My guess is that it is because of the instability Adam\n",
    "# has closer to the local minima. By manually reducing learning rate we make the extent of instability lower \n",
    "# (because learning rate in Adam is adaptive and we can only adjust the upper bound for neural net adjustments)\n",
    "\n",
    "encoder_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(encoder_optimizer, gamma=0.85)\n",
    "decoder_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(decoder_optimizer, gamma=0.85)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use full teacher forcing for the sake of simplicity, so we actually use encoder only to initialize decoder \n",
    "# hidden state. By feeding the decoder SOS tokemn, we signal it that we expect it to generate a transcription for \n",
    "# us.\n",
    "\n",
    "def train(input_tensor, target_tensor, max_length=max_wordlen):\n",
    "    criterion = nn.NLLLoss()\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0.0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        \n",
    "    sos = torch.zeros(1, 1, n_phones)\n",
    "    sos[0][0][0] = 1\n",
    "    sos = sos.to(device)\n",
    "    \n",
    "    decoder_input = sos\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        loss += criterion(decoder_output, torch.max(target_tensor[di], 1)[1])\n",
    "        decoder_input = target_tensor[di]\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quite useful functions to use for actual epoch time estimation.\n",
    "\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first train function takes one word, so we use a wrapper for it to train a whole epoch.\n",
    "\n",
    "def trainIters(encoder, decoder, print_every=1000, plot_every=100):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  \n",
    "    plot_loss_total = 0  \n",
    "    \n",
    "    training_pairs = [pairTensor(i)\n",
    "                      for i in tqdm(range(len(data)))]\n",
    "    \n",
    "    random.shuffle(training_pairs)\n",
    "\n",
    "    for iter in range(1, len(data) + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor.to(device), target_tensor.to(device))\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / len(data)),\n",
    "                                         iter, iter / len(data) * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plotting doesn't actually work for whatever reason.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f34443825e4bd08ab28e1e322aa557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4m 10s (- 65m 19s) (5000 6%) 1.3671\n",
      "8m 14s (- 60m 17s) (10000 12%) 1.0127\n",
      "12m 19s (- 56m 0s) (15000 18%) 0.8134\n",
      "16m 23s (- 51m 47s) (20000 24%) 0.6915\n",
      "20m 25s (- 47m 33s) (25000 30%) 0.5782\n",
      "24m 28s (- 43m 24s) (30000 36%) 0.4877\n",
      "28m 38s (- 39m 26s) (35000 42%) 0.4404\n",
      "33m 2s (- 35m 40s) (40000 48%) 0.3984\n",
      "37m 29s (- 31m 48s) (45000 54%) 0.3666\n",
      "41m 32s (- 27m 34s) (50000 60%) 0.3473\n",
      "45m 39s (- 23m 24s) (55000 66%) 0.3237\n",
      "49m 44s (- 19m 13s) (60000 72%) 0.3081\n",
      "53m 50s (- 15m 4s) (65000 78%) 0.2902\n",
      "57m 56s (- 10m 55s) (70000 84%) 0.2923\n",
      "62m 1s (- 6m 46s) (75000 90%) 0.2727\n",
      "66m 6s (- 2m 38s) (80000 96%) 0.2689\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06fdb3f5eab41ebb91a28317ab4bdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4m 13s (- 66m 5s) (5000 6%) 0.2386\n",
      "8m 19s (- 60m 54s) (10000 12%) 0.2394\n",
      "12m 26s (- 56m 34s) (15000 18%) 0.2300\n",
      "16m 30s (- 52m 10s) (20000 24%) 0.2280\n",
      "20m 35s (- 47m 56s) (25000 30%) 0.2254\n",
      "24m 40s (- 43m 45s) (30000 36%) 0.2218\n",
      "28m 46s (- 39m 37s) (35000 42%) 0.2184\n",
      "32m 53s (- 35m 31s) (40000 48%) 0.2149\n",
      "36m 58s (- 31m 22s) (45000 54%) 0.2088\n",
      "41m 4s (- 27m 16s) (50000 60%) 0.2130\n",
      "45m 9s (- 23m 8s) (55000 66%) 0.2058\n",
      "49m 14s (- 19m 1s) (60000 72%) 0.2110\n",
      "53m 19s (- 14m 55s) (65000 78%) 0.2046\n",
      "57m 27s (- 10m 49s) (70000 84%) 0.1956\n",
      "61m 33s (- 6m 43s) (75000 90%) 0.2000\n",
      "65m 39s (- 2m 37s) (80000 96%) 0.1915\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b79fea787e4b1fb4d5a6697d553a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4m 13s (- 66m 8s) (5000 6%) 0.1723\n",
      "8m 19s (- 60m 58s) (10000 12%) 0.1763\n",
      "12m 26s (- 56m 33s) (15000 18%) 0.1756\n",
      "16m 32s (- 52m 16s) (20000 24%) 0.1744\n",
      "20m 37s (- 47m 59s) (25000 30%) 0.1719\n",
      "24m 42s (- 43m 49s) (30000 36%) 0.1702\n",
      "28m 48s (- 39m 39s) (35000 42%) 0.1702\n",
      "32m 55s (- 35m 33s) (40000 48%) 0.1741\n",
      "37m 2s (- 31m 25s) (45000 54%) 0.1699\n",
      "41m 7s (- 27m 18s) (50000 60%) 0.1697\n",
      "45m 14s (- 23m 11s) (55000 66%) 0.1692\n",
      "49m 22s (- 19m 5s) (60000 72%) 0.1659\n",
      "53m 28s (- 14m 57s) (65000 78%) 0.1678\n",
      "57m 34s (- 10m 51s) (70000 84%) 0.1644\n",
      "61m 40s (- 6m 44s) (75000 90%) 0.1696\n",
      "65m 45s (- 2m 37s) (80000 96%) 0.1655\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bbbad7992041a4bc8ffb2004a31c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4m 14s (- 66m 22s) (5000 6%) 0.1510\n",
      "8m 22s (- 61m 15s) (10000 12%) 0.1506\n",
      "12m 27s (- 56m 39s) (15000 18%) 0.1452\n",
      "16m 33s (- 52m 18s) (20000 24%) 0.1491\n",
      "20m 41s (- 48m 9s) (25000 30%) 0.1465\n",
      "24m 47s (- 43m 56s) (30000 36%) 0.1446\n",
      "28m 53s (- 39m 46s) (35000 42%) 0.1423\n",
      "32m 58s (- 35m 36s) (40000 48%) 0.1443\n",
      "37m 5s (- 31m 28s) (45000 54%) 0.1483\n",
      "41m 11s (- 27m 21s) (50000 60%) 0.1417\n",
      "45m 19s (- 23m 14s) (55000 66%) 0.1479\n",
      "49m 25s (- 19m 6s) (60000 72%) 0.1453\n",
      "53m 31s (- 14m 59s) (65000 78%) 0.1487\n",
      "57m 39s (- 10m 52s) (70000 84%) 0.1439\n",
      "61m 43s (- 6m 44s) (75000 90%) 0.1401\n",
      "65m 50s (- 2m 37s) (80000 96%) 0.1472\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625afc7105194f33a3918c94c624bec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4m 14s (- 66m 19s) (5000 6%) 0.1283\n",
      "8m 22s (- 61m 17s) (10000 12%) 0.1293\n",
      "12m 27s (- 56m 40s) (15000 18%) 0.1262\n",
      "16m 34s (- 52m 22s) (20000 24%) 0.1316\n",
      "21m 0s (- 48m 53s) (25000 30%) 0.1333\n",
      "25m 6s (- 44m 30s) (30000 36%) 0.1275\n",
      "29m 11s (- 40m 11s) (35000 42%) 0.1277\n",
      "33m 17s (- 35m 57s) (40000 48%) 0.1277\n",
      "37m 23s (- 31m 44s) (45000 54%) 0.1311\n",
      "41m 30s (- 27m 33s) (50000 60%) 0.1278\n",
      "45m 38s (- 23m 23s) (55000 66%) 0.1299\n",
      "49m 42s (- 19m 13s) (60000 72%) 0.1264\n",
      "53m 48s (- 15m 3s) (65000 78%) 0.1270\n",
      "57m 55s (- 10m 55s) (70000 84%) 0.1268\n",
      "62m 1s (- 6m 46s) (75000 90%) 0.1322\n",
      "66m 8s (- 2m 38s) (80000 96%) 0.1288\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dfb1ab092848638faf4104d3bbc6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4m 15s (- 66m 37s) (5000 6%) 0.1170\n",
      "8m 19s (- 60m 55s) (10000 12%) 0.1153\n",
      "12m 26s (- 56m 33s) (15000 18%) 0.1154\n",
      "16m 34s (- 52m 21s) (20000 24%) 0.1180\n",
      "20m 41s (- 48m 9s) (25000 30%) 0.1143\n",
      "24m 48s (- 43m 58s) (30000 36%) 0.1158\n",
      "28m 55s (- 39m 49s) (35000 42%) 0.1214\n",
      "33m 0s (- 35m 38s) (40000 48%) 0.1138\n",
      "37m 6s (- 31m 29s) (45000 54%) 0.1184\n",
      "41m 14s (- 27m 22s) (50000 60%) 0.1148\n",
      "45m 21s (- 23m 14s) (55000 66%) 0.1179\n",
      "49m 29s (- 19m 7s) (60000 72%) 0.1160\n",
      "53m 35s (- 15m 0s) (65000 78%) 0.1120\n",
      "57m 43s (- 10m 52s) (70000 84%) 0.1151\n",
      "61m 49s (- 6m 45s) (75000 90%) 0.1232\n",
      "65m 56s (- 2m 37s) (80000 96%) 0.1164\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242ef225bdf340b8adba64a9155be3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4m 17s (- 67m 1s) (5000 6%) 0.1038\n",
      "8m 21s (- 61m 12s) (10000 12%) 0.1040\n",
      "12m 27s (- 56m 37s) (15000 18%) 0.1046\n",
      "16m 34s (- 52m 21s) (20000 24%) 0.1070\n",
      "20m 39s (- 48m 4s) (25000 30%) 0.1061\n",
      "24m 47s (- 43m 57s) (30000 36%) 0.1095\n",
      "28m 53s (- 39m 47s) (35000 42%) 0.1070\n",
      "32m 59s (- 35m 38s) (40000 48%) 0.1047\n",
      "37m 8s (- 31m 31s) (45000 54%) 0.1053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c29841bfbde5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdecoder_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-dc6ccbaada0e>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-60269cabcc74>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, max_length)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1 # I trained for around 10 to 20 epochs, setting 1 for the sake of demonstration\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    encoder_lr_scheduler.step()\n",
    "    decoder_lr_scheduler.step()\n",
    "    print(\"Epoch %d\" % (i + 1))\n",
    "    trainIters(encoder, decoder, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually NOT a good evaluation function, it just returns a generated translation for the word. TBA: actual\n",
    "# evaluation (with various metrcis and losses)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=max_wordlen):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = wordToTensor(sentence).to(device)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "\n",
    "        sos = torch.zeros(1, 1, n_phones)\n",
    "        sos[0][0][0] = 1\n",
    "        sos = sos.to(device)\n",
    "    \n",
    "        decoder_input = sos\n",
    "    \n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_chars = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            if topi.item() == 1:\n",
    "                break\n",
    "            else:\n",
    "                decoded_chars.append(rev_phonedict[topi.item() - 2])\n",
    "            \n",
    "            decoder_input = torch.zeros(1, 1, n_phones)\n",
    "            decoder_input[0][0][topi.item()] = 1\n",
    "            decoder_input = decoder_input.to(device)\n",
    "        \n",
    "        return \"_\".join(decoded_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So this actually works like a sanity check. If everything looks fair enough - we're good to go.\n",
    "\n",
    "for i in range(20):\n",
    "    print(data[i])\n",
    "    print(evaluate(encoder, decoder, data[i].split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test_x = test['Word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [evaluate(encoder, decoder, word) for word in tqdm(test_x)]\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.rename(columns={'Word':'Transcription'}, inplace=True) \n",
    "test['Transcription'] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I always write a brief summary of my submission in the filename. It's useful for keeping track of what ideas \n",
    "# worked and what didn't. It also may be useful for blending (as you may remember, it's better to use a set of \n",
    "# diverse architectures for weighted voting) I usually also provide CV score or validation acc/loss, but now I\n",
    "# dont have any.\n",
    "\n",
    "test.to_csv(\"lstm_one_hot_2_layer_bidirectional_16_epochs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
