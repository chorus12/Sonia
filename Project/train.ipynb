{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchsummary import summary \n",
    "from tqdm import trange \n",
    "\n",
    "import midi\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "batch_size = 512\n",
    "num_epochs = 4000\n",
    "learning_rate = 0.001\n",
    "hidden_size = 120\n",
    "step_size = 800\n",
    "gamma = 0.5\n",
    "dataset_path = 'Music/'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8493aa2280574bb1a4239b91247469a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR  Music/Pokemon Mystery Dungeon Explorers of Sky - Defend Globe.mid\n",
      "ERROR  Music/Sonic Unleashed - Windmill Isle Day.mid\n",
      "ERROR  Music/Double Dragon II The Revenge - Undersea Base.mid\n",
      "ERROR  Music/Super Mario Galaxy - End Title.mid\n",
      "ERROR  Music/Lufia  The Fortress of Doom - Ending.mid\n",
      "ERROR  Music/Kirby Super Star - Floria.mid\n",
      "ERROR  Music/Terranigma - Evergreen Forest.mid\n",
      "ERROR  Music/Mario Kart Wii - Mushroom Gorge.mid\n",
      "ERROR  Music/Golden Axe II - The Tower.mid\n",
      "ERROR  Music/Pokemon Diamond Version  Pokemon Pearl Version - Route 205 Day.mid\n",
      "ERROR  Music/Dance Dance Revolution Hottest Party - Love Shine.mid\n",
      "ERROR  Music/The Legend of Zelda Breath of the Wild - Spirit Orb Obtained.mid\n",
      "\n",
      "(328434, 96, 96)\n",
      "(5352,)\n"
     ]
    }
   ],
   "source": [
    "train_samples = []\n",
    "train_lengths = []\n",
    "\n",
    "for file in tqdm(os.listdir(dataset_path)):\n",
    "    try:\n",
    "        samples = midi.midi_to_samples(dataset_path + file)\n",
    "    except:\n",
    "        print (\"ERROR \", dataset_path + file)\n",
    "        continue\n",
    "                \n",
    "    if(len(samples) >= 8):\n",
    "        samples, lengths = utils.generate_add_centered_transpose(samples)\n",
    "        train_samples.extend(samples)\n",
    "        train_lengths.extend(lengths)\n",
    "        \n",
    "y_samples = np.array(train_samples)\n",
    "y_lengths = np.array(train_lengths)\n",
    "\n",
    "y_test_song = np.expand_dims(np.copy(y_samples[0 : 16]), axis = 0)\n",
    "\n",
    "y_samples = y_samples[2 * y_lengths[0] : ]\n",
    "y_lengths = y_lengths[2 : ]\n",
    "\n",
    "print(y_samples.shape)\n",
    "print(y_lengths.shape)\n",
    "\n",
    "num_samples = y_samples.shape[0]\n",
    "num_songs = y_lengths.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5352/5352 [00:00<00:00, 14242.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328434\n",
      "328434\n",
      "(5352, 1)\n",
      "(5352, 16, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "x_shape = (y_lengths.shape[0], 1)\n",
    "y_shape = (y_lengths.shape[0], 16) + y_samples.shape[1:]\n",
    "\n",
    "x_orig = np.expand_dims(np.arange(x_shape[0]), axis=-1)\n",
    "y_orig = np.zeros(y_shape, dtype=y_samples.dtype)\n",
    "\n",
    "cur_ix = 0\n",
    "\n",
    "for i in trange(num_songs):\n",
    "    ix = i\n",
    "    end_ix = cur_ix + y_lengths[i]\n",
    "        \n",
    "    for j in range(16):\n",
    "        k = j % (end_ix - cur_ix)\n",
    "        y_orig[ix,j] = y_samples[cur_ix + k]\n",
    "            \n",
    "    cur_ix = end_ix\n",
    "\n",
    "print(end_ix)\n",
    "print(num_samples)\n",
    "assert(end_ix == num_samples)\n",
    "\n",
    "x_train = np.copy(x_orig)\n",
    "y_train = np.copy(y_orig)\n",
    "\n",
    "np.save('samples.npy', y_orig)\n",
    "y_orig_tensor = torch.from_numpy(y_orig).to(device)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our autoencoder model\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(96 * 96, 2000)\n",
    "        self.fc2 = nn.Linear(2000, 200)\n",
    "        self.fc3 = nn.Linear(16 * 200, 1600)\n",
    "        self.fc4 = nn.Linear(1600, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.bn1(self.fc4(x))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, 1600)\n",
    "        self.fc2 = nn.Linear(1600, 16 * 200)\n",
    "        self.fc3 = nn.Linear(200, 2000)\n",
    "        self.fc4 = nn.Linear(2000, 96 * 96)\n",
    "        self.bn1 = nn.BatchNorm1d(1600)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, 16, 200)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        \n",
    "        return x.view(-1, 16, 96, 96)\n",
    "    \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def encoder_forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def decoder_forward(self, x):\n",
    "        x = self.dec(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Autoencoder().to(device)\n",
    "summary(model, (16, 96, 96))\n",
    "\n",
    "error = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDI_data(Dataset):\n",
    "    def __init__(self, tX):\n",
    "            self.X = tX\n",
    "            self.y = tX\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofs = 0\n",
    "\n",
    "def make_rand_songs(write_dir, rand_vecs, thresh):\n",
    "    for i in range(rand_vecs.shape[0]):\n",
    "        x_rand = torch.from_numpy(rand_vecs[i : i + 1]).to(device).float()\n",
    "        with torch.no_grad(): \n",
    "            y_song = model.decoder_forward(x_rand).cpu().numpy()\n",
    "            midi.samples_to_midi(y_song[0], write_dir + 'rand' + str(i) + '.mid', 16, thresh)\n",
    "            \n",
    "def train(epoch):\n",
    "    global ofs\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    cur_ix = 0\n",
    "\n",
    "    for i in range(num_songs):\n",
    "        end_ix = cur_ix + y_lengths[i]\n",
    "            \n",
    "        for j in range(16):\n",
    "            k = (j + ofs) % (end_ix - cur_ix)\n",
    "            y_train[i,j] = y_samples[cur_ix + k]\n",
    "                \n",
    "        cur_ix = end_ix\n",
    "    \n",
    "    assert(end_ix == num_samples)\n",
    "    ofs += 1\n",
    "    \n",
    "    \n",
    "    train_dataset = MIDI_data(y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = False, pin_memory = True)\n",
    "    \n",
    "    running_loss = 0.0 \n",
    "\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(x.float())\n",
    "\n",
    "        loss = error(outputs, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, (i + 1) * len(x), len(train_loader.dataset),\n",
    "                    100. * (i + 1) / len(train_loader), running_loss / 5))\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            \n",
    "def evaluate(thresh):\n",
    "    model.eval()\n",
    "\n",
    "    y_test_song_tensor = torch.from_numpy(y_test_song).to(device).float()\n",
    "\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        y_song = model(y_test_song_tensor).cpu().numpy()[0]\n",
    "\n",
    "    midi.samples_to_midi(y_song, 'Output/' + 'test.mid', 16)        \n",
    "    midi.samples_to_midi(y_test_song[0], 'Output/' + 'target.mid', 16)\n",
    "\n",
    "    rand_vecs = np.random.normal(0.0, 1.0, (10, hidden_size))\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        x_enc = np.squeeze(model.encoder_forward(y_orig_tensor.float()).cpu().numpy())\n",
    "\n",
    "    x_mean = np.mean(x_enc, axis=0)\n",
    "    x_stds = np.std(x_enc, axis=0)\n",
    "    x_cov = np.cov((x_enc - x_mean).T)\n",
    "    u, s, v = np.linalg.svd(x_cov)\n",
    "    e = np.sqrt(s)\n",
    "\n",
    "    x_vecs = x_mean + np.dot(rand_vecs * e, v)\n",
    "    make_rand_songs('Output/', x_vecs, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    lr_scheduler.step()\n",
    "    train(epoch)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        evaluate(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'States/model_state_MSE_config')\n",
    "\n",
    "def save_config():\n",
    "    with open('MSE_config.txt', 'w') as fout:\n",
    "        fout.write('BATCH_SIZE:  ' + str(batch_size) + '\\n')\n",
    "        fout.write('NUM_EPOCHS:  ' + str(num_epochs) + '\\n')\n",
    "        fout.write('LR:  ' + str(learning_rate) + '\\n')\n",
    "        fout.write('HIDDEN_SIZE:  ' + str(hidden_size) + '\\n')\n",
    "        fout.write('STEP_SIZE:  ' + str(step_size) + '\\n')\n",
    "        fout.write('GAMMA:  ' + str(gamma) + '\\n')\n",
    "        \n",
    "save_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
