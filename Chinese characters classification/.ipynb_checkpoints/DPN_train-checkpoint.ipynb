{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "10dc6168c78bffe190597d23394ff54e698792d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "h, w = 64, 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "8db07f3dfad330731c1e340995dad80abe7d4293"
   },
   "outputs": [],
   "source": [
    "def resize (img):\n",
    "    im = Image.fromarray(img)\n",
    "    im.thumbnail((h, w), Image.ANTIALIAS)\n",
    "    im = np.array(im).astype('float32')\n",
    "    return np.pad(im, (((h - im.shape[0]) // 2, (h - im.shape[0] + 1) // 2), ((w - im.shape[1]) // 2, (w - im.shape[1] + 1) // 2)), 'constant', constant_values=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d70fc17f961c7b79542dca0400e8d9b0d4aef225"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332987/332987 [01:13<00:00, 4501.82it/s]\n"
     ]
    }
   ],
   "source": [
    "data1 = np.load('train-1.npy')\n",
    "data2 = np.load('train-2.npy')\n",
    "data3 = np.load('train-3.npy')\n",
    "data4 = np.load('train-4.npy')\n",
    "train = np.concatenate((data1, data2, data3, data4), axis=0)\n",
    "\n",
    "train[:, 0] = [resize(img) for img in tqdm(train[:, 0])]\n",
    "\n",
    "del data1\n",
    "del data2\n",
    "del data3 \n",
    "del data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c528ffdc5ae1d5d1340ba5cd70764812d1c062e1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "for n, (image, tag) in enumerate(train, 1):\n",
    "    if n > 64:\n",
    "        break\n",
    "    plt.subplot(8, 8, n)\n",
    "    plt.title(tag)\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bf009b1d56cd027683ba41617bb5b2334bd9f69"
   },
   "outputs": [],
   "source": [
    "print(train[10, 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c2dff08b62560cb19009d44423295048046e8143"
   },
   "outputs": [],
   "source": [
    "dct = dict(zip(range(1000), np.unique(train[:, 1])))\n",
    "dct = {v:k for k,v in dct.items()}\n",
    "\n",
    "train[:, 1] = [dct[code] for code in train[:, 1]]\n",
    "\n",
    "#train, test = train_test_split(train, test_size=0.2, random_state=113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "2bd7c9c37920e0dd2bb5dbbe562bbb167cf43031"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332987/332987 [00:00<00:00, 1395648.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x_np, train_y_np = np.array([i[:, :, np.newaxis] for i in tqdm(train[:, 0])]), np.array(train[:, 1], dtype='int32')\n",
    "del train\n",
    "#test_x_np, test_y_np = np.array([i[:, :, np.newaxis] for i in tqdm(test[:, 0])]), np.array(test[:, 1], dtype='int32')\n",
    "#del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4f9a4f32edb38a2ee2833ad53b841638e05c6955"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "feabf686c3d2d23205c502d83c07133f34577f07"
   },
   "outputs": [],
   "source": [
    "class Hieroglyph_data(Dataset):\n",
    "    def __init__(self, tX, tY = None,\n",
    "                 transform = transforms.Compose(\n",
    "                     [transforms.ToPILImage(), \n",
    "                      transforms.ToTensor(), \n",
    "                      transforms.Normalize(mean=(0.5,), std=(0.5,))]), train=True):\n",
    "        \n",
    "        if train == True:\n",
    "            self.X = tX\n",
    "            self.y = torch.Tensor(tY).type(torch.LongTensor)\n",
    "            self.transform = transform\n",
    "            self.train = True\n",
    "            \n",
    "        else:\n",
    "            self.X = tX\n",
    "            self.y = None\n",
    "            self.transform = transform\n",
    "            self.train = False\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train == True:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5aaf43cd790df4031e570e6c7ee64dd78e67370a"
   },
   "outputs": [],
   "source": [
    "train_dataset = Hieroglyph_data(train_x_np, train_y_np, transform = transforms.Compose(\n",
    "                                [transforms.ToPILImage(), \n",
    "                                 transforms.RandomAffine(\n",
    "                                 degrees=(-10, 10), \n",
    "                                 translate=(.1, .1), \n",
    "                                 scale=(.9, 1.1),\n",
    "                                 shear=(-10, 10)),\n",
    "                                 transforms.ToTensor(), \n",
    "                                 transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "\n",
    "#test_dataset = Hieroglyph_data(test_x_np, test_y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "664d254b99b3232b7fb54ca1d3a6da39781c2d8c"
   },
   "outputs": [],
   "source": [
    "num_classes = 1000\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, pin_memory = True)\n",
    "#test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "af8b7392a2eebc0722b360ffe4888d8495dba1d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 30, 30]           1,600\n",
      "       BatchNorm2d-2           [-1, 64, 30, 30]             128\n",
      "            Conv2d-3           [-1, 96, 30, 30]           6,144\n",
      "       BatchNorm2d-4           [-1, 96, 30, 30]             192\n",
      "            Conv2d-5           [-1, 96, 30, 30]           2,592\n",
      "       BatchNorm2d-6           [-1, 96, 30, 30]             192\n",
      "            Conv2d-7          [-1, 272, 30, 30]          26,112\n",
      "       BatchNorm2d-8          [-1, 272, 30, 30]             544\n",
      "            Conv2d-9          [-1, 272, 30, 30]          17,408\n",
      "      BatchNorm2d-10          [-1, 272, 30, 30]             544\n",
      "       Bottleneck-11          [-1, 288, 30, 30]               0\n",
      "           Conv2d-12           [-1, 96, 30, 30]          27,648\n",
      "      BatchNorm2d-13           [-1, 96, 30, 30]             192\n",
      "           Conv2d-14           [-1, 96, 30, 30]           2,592\n",
      "      BatchNorm2d-15           [-1, 96, 30, 30]             192\n",
      "           Conv2d-16          [-1, 272, 30, 30]          26,112\n",
      "      BatchNorm2d-17          [-1, 272, 30, 30]             544\n",
      "       Bottleneck-18          [-1, 304, 30, 30]               0\n",
      "           Conv2d-19           [-1, 96, 30, 30]          29,184\n",
      "      BatchNorm2d-20           [-1, 96, 30, 30]             192\n",
      "           Conv2d-21           [-1, 96, 30, 30]           2,592\n",
      "      BatchNorm2d-22           [-1, 96, 30, 30]             192\n",
      "           Conv2d-23          [-1, 272, 30, 30]          26,112\n",
      "      BatchNorm2d-24          [-1, 272, 30, 30]             544\n",
      "       Bottleneck-25          [-1, 320, 30, 30]               0\n",
      "           Conv2d-26          [-1, 192, 30, 30]          61,440\n",
      "      BatchNorm2d-27          [-1, 192, 30, 30]             384\n",
      "           Conv2d-28          [-1, 192, 15, 15]          10,368\n",
      "      BatchNorm2d-29          [-1, 192, 15, 15]             384\n",
      "           Conv2d-30          [-1, 544, 15, 15]         104,448\n",
      "      BatchNorm2d-31          [-1, 544, 15, 15]           1,088\n",
      "           Conv2d-32          [-1, 544, 15, 15]         174,080\n",
      "      BatchNorm2d-33          [-1, 544, 15, 15]           1,088\n",
      "       Bottleneck-34          [-1, 576, 15, 15]               0\n",
      "           Conv2d-35          [-1, 192, 15, 15]         110,592\n",
      "      BatchNorm2d-36          [-1, 192, 15, 15]             384\n",
      "           Conv2d-37          [-1, 192, 15, 15]          10,368\n",
      "      BatchNorm2d-38          [-1, 192, 15, 15]             384\n",
      "           Conv2d-39          [-1, 544, 15, 15]         104,448\n",
      "      BatchNorm2d-40          [-1, 544, 15, 15]           1,088\n",
      "       Bottleneck-41          [-1, 608, 15, 15]               0\n",
      "           Conv2d-42          [-1, 192, 15, 15]         116,736\n",
      "      BatchNorm2d-43          [-1, 192, 15, 15]             384\n",
      "           Conv2d-44          [-1, 192, 15, 15]          10,368\n",
      "      BatchNorm2d-45          [-1, 192, 15, 15]             384\n",
      "           Conv2d-46          [-1, 544, 15, 15]         104,448\n",
      "      BatchNorm2d-47          [-1, 544, 15, 15]           1,088\n",
      "       Bottleneck-48          [-1, 640, 15, 15]               0\n",
      "           Conv2d-49          [-1, 192, 15, 15]         122,880\n",
      "      BatchNorm2d-50          [-1, 192, 15, 15]             384\n",
      "           Conv2d-51          [-1, 192, 15, 15]          10,368\n",
      "      BatchNorm2d-52          [-1, 192, 15, 15]             384\n",
      "           Conv2d-53          [-1, 544, 15, 15]         104,448\n",
      "      BatchNorm2d-54          [-1, 544, 15, 15]           1,088\n",
      "       Bottleneck-55          [-1, 672, 15, 15]               0\n",
      "           Conv2d-56          [-1, 384, 15, 15]         258,048\n",
      "      BatchNorm2d-57          [-1, 384, 15, 15]             768\n",
      "           Conv2d-58            [-1, 384, 8, 8]          41,472\n",
      "      BatchNorm2d-59            [-1, 384, 8, 8]             768\n",
      "           Conv2d-60           [-1, 1048, 8, 8]         402,432\n",
      "      BatchNorm2d-61           [-1, 1048, 8, 8]           2,096\n",
      "           Conv2d-62           [-1, 1048, 8, 8]         704,256\n",
      "      BatchNorm2d-63           [-1, 1048, 8, 8]           2,096\n",
      "       Bottleneck-64           [-1, 1072, 8, 8]               0\n",
      "           Conv2d-65            [-1, 384, 8, 8]         411,648\n",
      "      BatchNorm2d-66            [-1, 384, 8, 8]             768\n",
      "           Conv2d-67            [-1, 384, 8, 8]          41,472\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "           Conv2d-69           [-1, 1048, 8, 8]         402,432\n",
      "      BatchNorm2d-70           [-1, 1048, 8, 8]           2,096\n",
      "       Bottleneck-71           [-1, 1096, 8, 8]               0\n",
      "           Conv2d-72            [-1, 384, 8, 8]         420,864\n",
      "      BatchNorm2d-73            [-1, 384, 8, 8]             768\n",
      "           Conv2d-74            [-1, 384, 8, 8]          41,472\n",
      "      BatchNorm2d-75            [-1, 384, 8, 8]             768\n",
      "           Conv2d-76           [-1, 1048, 8, 8]         402,432\n",
      "      BatchNorm2d-77           [-1, 1048, 8, 8]           2,096\n",
      "       Bottleneck-78           [-1, 1120, 8, 8]               0\n",
      "           Conv2d-79            [-1, 384, 8, 8]         430,080\n",
      "      BatchNorm2d-80            [-1, 384, 8, 8]             768\n",
      "           Conv2d-81            [-1, 384, 8, 8]          41,472\n",
      "      BatchNorm2d-82            [-1, 384, 8, 8]             768\n",
      "           Conv2d-83           [-1, 1048, 8, 8]         402,432\n",
      "      BatchNorm2d-84           [-1, 1048, 8, 8]           2,096\n",
      "       Bottleneck-85           [-1, 1144, 8, 8]               0\n",
      "           Conv2d-86            [-1, 384, 8, 8]         439,296\n",
      "      BatchNorm2d-87            [-1, 384, 8, 8]             768\n",
      "           Conv2d-88            [-1, 384, 8, 8]          41,472\n",
      "      BatchNorm2d-89            [-1, 384, 8, 8]             768\n",
      "           Conv2d-90           [-1, 1048, 8, 8]         402,432\n",
      "      BatchNorm2d-91           [-1, 1048, 8, 8]           2,096\n",
      "       Bottleneck-92           [-1, 1168, 8, 8]               0\n",
      "           Conv2d-93            [-1, 384, 8, 8]         448,512\n",
      "      BatchNorm2d-94            [-1, 384, 8, 8]             768\n",
      "           Conv2d-95            [-1, 384, 8, 8]          41,472\n",
      "      BatchNorm2d-96            [-1, 384, 8, 8]             768\n",
      "           Conv2d-97           [-1, 1048, 8, 8]         402,432\n",
      "      BatchNorm2d-98           [-1, 1048, 8, 8]           2,096\n",
      "       Bottleneck-99           [-1, 1192, 8, 8]               0\n",
      "          Conv2d-100            [-1, 384, 8, 8]         457,728\n",
      "     BatchNorm2d-101            [-1, 384, 8, 8]             768\n",
      "          Conv2d-102            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-103            [-1, 384, 8, 8]             768\n",
      "          Conv2d-104           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-105           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-106           [-1, 1216, 8, 8]               0\n",
      "          Conv2d-107            [-1, 384, 8, 8]         466,944\n",
      "     BatchNorm2d-108            [-1, 384, 8, 8]             768\n",
      "          Conv2d-109            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-110            [-1, 384, 8, 8]             768\n",
      "          Conv2d-111           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-112           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-113           [-1, 1240, 8, 8]               0\n",
      "          Conv2d-114            [-1, 384, 8, 8]         476,160\n",
      "     BatchNorm2d-115            [-1, 384, 8, 8]             768\n",
      "          Conv2d-116            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-117            [-1, 384, 8, 8]             768\n",
      "          Conv2d-118           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-119           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-120           [-1, 1264, 8, 8]               0\n",
      "          Conv2d-121            [-1, 384, 8, 8]         485,376\n",
      "     BatchNorm2d-122            [-1, 384, 8, 8]             768\n",
      "          Conv2d-123            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-124            [-1, 384, 8, 8]             768\n",
      "          Conv2d-125           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-126           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-127           [-1, 1288, 8, 8]               0\n",
      "          Conv2d-128            [-1, 384, 8, 8]         494,592\n",
      "     BatchNorm2d-129            [-1, 384, 8, 8]             768\n",
      "          Conv2d-130            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-131            [-1, 384, 8, 8]             768\n",
      "          Conv2d-132           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-133           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-134           [-1, 1312, 8, 8]               0\n",
      "          Conv2d-135            [-1, 384, 8, 8]         503,808\n",
      "     BatchNorm2d-136            [-1, 384, 8, 8]             768\n",
      "          Conv2d-137            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-138            [-1, 384, 8, 8]             768\n",
      "          Conv2d-139           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-140           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-141           [-1, 1336, 8, 8]               0\n",
      "          Conv2d-142            [-1, 384, 8, 8]         513,024\n",
      "     BatchNorm2d-143            [-1, 384, 8, 8]             768\n",
      "          Conv2d-144            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-145            [-1, 384, 8, 8]             768\n",
      "          Conv2d-146           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-147           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-148           [-1, 1360, 8, 8]               0\n",
      "          Conv2d-149            [-1, 384, 8, 8]         522,240\n",
      "     BatchNorm2d-150            [-1, 384, 8, 8]             768\n",
      "          Conv2d-151            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-152            [-1, 384, 8, 8]             768\n",
      "          Conv2d-153           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-154           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-155           [-1, 1384, 8, 8]               0\n",
      "          Conv2d-156            [-1, 384, 8, 8]         531,456\n",
      "     BatchNorm2d-157            [-1, 384, 8, 8]             768\n",
      "          Conv2d-158            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-159            [-1, 384, 8, 8]             768\n",
      "          Conv2d-160           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-161           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-162           [-1, 1408, 8, 8]               0\n",
      "          Conv2d-163            [-1, 384, 8, 8]         540,672\n",
      "     BatchNorm2d-164            [-1, 384, 8, 8]             768\n",
      "          Conv2d-165            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-166            [-1, 384, 8, 8]             768\n",
      "          Conv2d-167           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-168           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-169           [-1, 1432, 8, 8]               0\n",
      "          Conv2d-170            [-1, 384, 8, 8]         549,888\n",
      "     BatchNorm2d-171            [-1, 384, 8, 8]             768\n",
      "          Conv2d-172            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-173            [-1, 384, 8, 8]             768\n",
      "          Conv2d-174           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-175           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-176           [-1, 1456, 8, 8]               0\n",
      "          Conv2d-177            [-1, 384, 8, 8]         559,104\n",
      "     BatchNorm2d-178            [-1, 384, 8, 8]             768\n",
      "          Conv2d-179            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-180            [-1, 384, 8, 8]             768\n",
      "          Conv2d-181           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-182           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-183           [-1, 1480, 8, 8]               0\n",
      "          Conv2d-184            [-1, 384, 8, 8]         568,320\n",
      "     BatchNorm2d-185            [-1, 384, 8, 8]             768\n",
      "          Conv2d-186            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-187            [-1, 384, 8, 8]             768\n",
      "          Conv2d-188           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-189           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-190           [-1, 1504, 8, 8]               0\n",
      "          Conv2d-191            [-1, 384, 8, 8]         577,536\n",
      "     BatchNorm2d-192            [-1, 384, 8, 8]             768\n",
      "          Conv2d-193            [-1, 384, 8, 8]          41,472\n",
      "     BatchNorm2d-194            [-1, 384, 8, 8]             768\n",
      "          Conv2d-195           [-1, 1048, 8, 8]         402,432\n",
      "     BatchNorm2d-196           [-1, 1048, 8, 8]           2,096\n",
      "      Bottleneck-197           [-1, 1528, 8, 8]               0\n",
      "          Conv2d-198            [-1, 768, 8, 8]       1,173,504\n",
      "     BatchNorm2d-199            [-1, 768, 8, 8]           1,536\n",
      "          Conv2d-200            [-1, 768, 4, 4]         165,888\n",
      "     BatchNorm2d-201            [-1, 768, 4, 4]           1,536\n",
      "          Conv2d-202           [-1, 2176, 4, 4]       1,671,168\n",
      "     BatchNorm2d-203           [-1, 2176, 4, 4]           4,352\n",
      "          Conv2d-204           [-1, 2176, 4, 4]       3,324,928\n",
      "     BatchNorm2d-205           [-1, 2176, 4, 4]           4,352\n",
      "      Bottleneck-206           [-1, 2304, 4, 4]               0\n",
      "          Conv2d-207            [-1, 768, 4, 4]       1,769,472\n",
      "     BatchNorm2d-208            [-1, 768, 4, 4]           1,536\n",
      "          Conv2d-209            [-1, 768, 4, 4]         165,888\n",
      "     BatchNorm2d-210            [-1, 768, 4, 4]           1,536\n",
      "          Conv2d-211           [-1, 2176, 4, 4]       1,671,168\n",
      "     BatchNorm2d-212           [-1, 2176, 4, 4]           4,352\n",
      "      Bottleneck-213           [-1, 2432, 4, 4]               0\n",
      "          Conv2d-214            [-1, 768, 4, 4]       1,867,776\n",
      "     BatchNorm2d-215            [-1, 768, 4, 4]           1,536\n",
      "          Conv2d-216            [-1, 768, 4, 4]         165,888\n",
      "     BatchNorm2d-217            [-1, 768, 4, 4]           1,536\n",
      "          Conv2d-218           [-1, 2176, 4, 4]       1,671,168\n",
      "     BatchNorm2d-219           [-1, 2176, 4, 4]           4,352\n",
      "      Bottleneck-220           [-1, 2560, 4, 4]               0\n",
      "          Linear-221                 [-1, 1000]       2,561,000\n",
      "================================================================\n",
      "Total params: 36,771,896\n",
      "Trainable params: 36,771,896\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 105.71\n",
      "Params size (MB): 140.27\n",
      "Estimated Total Size (MB): 246.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''Dual Path Networks in PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, last_planes, in_planes, out_planes, dense_depth, stride, first_layer):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.out_planes = out_planes\n",
    "        self.dense_depth = dense_depth\n",
    "\n",
    "        self.conv1 = nn.Conv2d(last_planes, in_planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv3 = nn.Conv2d(in_planes, out_planes+dense_depth, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes+dense_depth)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if first_layer:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(last_planes, out_planes+dense_depth, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes+dense_depth)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        x = self.shortcut(x)\n",
    "        d = self.out_planes\n",
    "        out = torch.cat([x[:,:d,:,:]+out[:,:d,:,:], x[:,d:,:,:], out[:,d:,:,:]], 1)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DPN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(DPN, self).__init__()\n",
    "        in_planes, out_planes = cfg['in_planes'], cfg['out_planes']\n",
    "        num_blocks, dense_depth = cfg['num_blocks'], cfg['dense_depth']\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.last_planes = 64\n",
    "        self.layer1 = self._make_layer(in_planes[0], out_planes[0], num_blocks[0], dense_depth[0], stride=1)\n",
    "        self.layer2 = self._make_layer(in_planes[1], out_planes[1], num_blocks[1], dense_depth[1], stride=2)\n",
    "        self.layer3 = self._make_layer(in_planes[2], out_planes[2], num_blocks[2], dense_depth[2], stride=2)\n",
    "        self.layer4 = self._make_layer(in_planes[3], out_planes[3], num_blocks[3], dense_depth[3], stride=2)\n",
    "        self.linear = nn.Linear(out_planes[3]+(num_blocks[3]+1)*dense_depth[3], 1000)\n",
    "\n",
    "    def _make_layer(self, in_planes, out_planes, num_blocks, dense_depth, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for i,stride in enumerate(strides):\n",
    "            layers.append(Bottleneck(self.last_planes, in_planes, out_planes, dense_depth, stride, i==0))\n",
    "            self.last_planes = out_planes + (i+2) * dense_depth\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def DPN26():\n",
    "    cfg = {\n",
    "        'in_planes': (96,192,384,768),\n",
    "        'out_planes': (256,512,1024,2048),\n",
    "        'num_blocks': (2,2,2,2),\n",
    "        'dense_depth': (16,32,24,128)\n",
    "    }\n",
    "    return DPN(cfg)\n",
    "\n",
    "def DPN92():\n",
    "    cfg = {\n",
    "        'in_planes': (96,192,384,768),\n",
    "        'out_planes': (256,512,1024,2048),\n",
    "        'num_blocks': (3,4,20,3),\n",
    "        'dense_depth': (16,32,24,128)\n",
    "    }\n",
    "    return DPN(cfg)\n",
    "\n",
    "model = DPN92()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, (1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6ba1b8e027b1f51340dff46820798cb0794560ec"
   },
   "outputs": [],
   "source": [
    "error = nn.CrossEntropyLoss()\n",
    "#error = error.to(device)\n",
    "\n",
    "learning_rate = 0.002\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "6f203a72e519b9c110b0759ee1fcfd34fe039dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtf\n"
     ]
    }
   ],
   "source": [
    "print('wtf')\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.view(-1, 1, h, w).to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1)% 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (i+ 1) * len(images), len(train_loader.dataset),\n",
    "                100. * (i + 1) / len(train_loader), loss.item()))\n",
    "            \n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            images, labels = images.view(-1, 1, h, w).to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss += F.cross_entropy(outputs, labels, size_average=False).item()\n",
    "\n",
    "            pred = outputs.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "b1072e43e1d68c55266189ffd0328470b15d88f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [3200/332987 (1%)]\tLoss: 6.934428\n",
      "Train Epoch: 0 [6400/332987 (2%)]\tLoss: 6.909641\n",
      "Train Epoch: 0 [9600/332987 (3%)]\tLoss: 6.914239\n",
      "Train Epoch: 0 [12800/332987 (4%)]\tLoss: 6.903149\n",
      "Train Epoch: 0 [16000/332987 (5%)]\tLoss: 6.922633\n",
      "Train Epoch: 0 [19200/332987 (6%)]\tLoss: 6.906963\n",
      "Train Epoch: 0 [22400/332987 (7%)]\tLoss: 6.916557\n",
      "Train Epoch: 0 [25600/332987 (8%)]\tLoss: 6.917842\n",
      "Train Epoch: 0 [28800/332987 (9%)]\tLoss: 6.900146\n",
      "Train Epoch: 0 [32000/332987 (10%)]\tLoss: 6.916846\n",
      "Train Epoch: 0 [35200/332987 (11%)]\tLoss: 6.907202\n",
      "Train Epoch: 0 [38400/332987 (12%)]\tLoss: 6.913777\n",
      "Train Epoch: 0 [41600/332987 (12%)]\tLoss: 6.918989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-96d08e43b4da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#    evaluate(test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-59ef46787021>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7774db255068>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7774db255068>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    lr_scheduler.step()\n",
    "    train(epoch)\n",
    "#    evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x_np\n",
    "del train_y_np\n",
    "#del test_x_np\n",
    "#del test_y_np\n",
    "del train_loader\n",
    "#del test_loader\n",
    "del train_dataset\n",
    "#del test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14476d7c3d1a803d26b9631c340152777557698b"
   },
   "outputs": [],
   "source": [
    "pred = np.load('test.npy')\n",
    "pred = np.array([resize(img) for img in tqdm(pred)])\n",
    "pred = np.array([i[:, :, np.newaxis] for i in tqdm(pred)])\n",
    "pred_dataset = Hieroglyph_data(pred, train = False)\n",
    "pred_loader = torch.utils.data.DataLoader(pred_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aca139420dc0c04f4062076f1d56facf7721a98d"
   },
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, images in enumerate(data_loader):\n",
    "            images = Variable(images.view(-1, 1, h, w))\n",
    "\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            pred = outputs.cpu().data.max(1, keepdim=True)[1]\n",
    "\n",
    "            test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18d93e79f4c49227ef3179a642fdf10ee927acc4"
   },
   "outputs": [],
   "source": [
    "pred_y = prediciton(pred_loader)\n",
    "pred_y = pred_y.cpu().numpy().flatten()\n",
    "\n",
    "dct = {v:k for k,v in dct.items()}\n",
    "\n",
    "pred_y = [dct[code] for code in pred_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46da802ed7e355968bfbc3fa760add2c238ea8f4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.Series(pred_y, name=\"Category\", dtype = 'object')\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,83248), name = \"Id\", dtype='object'), results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"dpn92_64_64_no_validation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3c7ba3c52ce70e7ca473ee77a22130b16975382"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
